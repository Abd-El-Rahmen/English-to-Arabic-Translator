{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-gKMKT5j8rz",
    "outputId": "f4a7e243-37a9-4ebc-871d-2ff784b9e57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
      "Dataset URL: https://www.kaggle.com/datasets/ahmedashrafahmed/arabic-to-english-sentences-dataset\n",
      "License(s): unknown\n",
      "Downloading arabic-to-english-sentences-dataset.zip to /content\n",
      "  0% 0.00/493k [00:00<?, ?B/s]\n",
      "100% 493k/493k [00:00<00:00, 122MB/s]\n",
      "Archive:  arabic-to-english-sentences-dataset.zip\n",
      "  inflating: _about.txt              \n",
      "  inflating: ara.txt                 \n",
      "_about.txt  arabic-to-english-sentences-dataset.zip  ara.txt  sample_data\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset from kaggle (ahmedashrafahmed/arabic-to-english-sentences-dataset)\n",
    "\n",
    "\"\"\"\n",
    "  Note :\n",
    "    if you want to download the datset you need to Set up Kaggle API Key then uploading the kaggle.json file\n",
    "\"\"\"\n",
    "\n",
    "!pip install kaggle\n",
    "import os\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "os.rename('kaggle.json', '/root/.kaggle/kaggle.json')\n",
    "os.chmod('/root/.kaggle/kaggle.json', 600)\n",
    "!kaggle datasets download ahmedashrafahmed/arabic-to-english-sentences-dataset\n",
    "!unzip arabic-to-english-sentences-dataset.zip\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YV4zxUOP2SSq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDfmWLjCkCc-",
    "outputId": "ca3c090b-1108-42e1-ca7f-82524ad9b340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    en_s            ar_s                                        Attribution\n",
      "0    Hi.         مرحبًا.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
      "1   Run!           اركض!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
      "2  Duck!      اخفض رأسك!  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
      "3  Duck!     اخفضي رأسك!  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
      "4  Duck!  اخفضوا رؤوسكم!  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'ara.txt'\n",
    "\n",
    "# transforming the file into a dataframe\n",
    "df = pd.read_csv(file_path, delimiter='\\t', header=None, names=[\"en_s\", \"ar_s\", \"Attribution\"])\n",
    "\n",
    "# displaying the first few rows of the dataframe to verify the content\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wz459YhPkHAe",
    "outputId": "00ef97bc-1bdb-480c-976a-10364ecfd8d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "# preprocessing + tokenization\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nlp_arabic = spacy.blank('ar')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+' , ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\u0621-\\u064A\\s\\u060C\\u061F\\u0640\\u0660-\\u0669\\u06F0-\\u06F9\\u066C\\u062C\\u0646\\u0645\\u062A\\u0644\\u064A\\u0634.]', '', text)\n",
    "    return text\n",
    "\n",
    "def tokenize_english(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def tokenize_arabic(text):\n",
    "    doc = nlp_arabic(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['en'] = df['en_s'].apply(clean_text)\n",
    "    df['ar'] = df['ar_s'].apply(clean_text)\n",
    "\n",
    "    df['en_tokens'] = df['en'].apply(tokenize_english)\n",
    "    df['ar_tokens'] = df['ar'].apply(tokenize_arabic)\n",
    "\n",
    "    return df[['en_tokens', 'ar_tokens']]\n",
    "\n",
    "data = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wj9DW5IKkJib",
    "outputId": "51442510-215a-47e0-a9bf-ef9a9e63f1b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-630b48868c45>:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['ar_ids'] = encode_sentences(data['ar_tokens'],ar_vocab, max_len=max_len)\n",
      "<ipython-input-24-630b48868c45>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['en_ids'] = encode_sentences(data['en_tokens'],en_vocab, max_len=max_len)\n"
     ]
    }
   ],
   "source": [
    "# building vocabulary + encoding\n",
    "from collections import Counter\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    flat_tokens = [token for sentence in sentences for token in sentence]\n",
    "    token_counts = Counter(flat_tokens)\n",
    "\n",
    "    vocab = {token: idx+4 for idx, (token, count) in enumerate(token_counts.items())}\n",
    "    # adding special tokens\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    vocab['<START>'] = 2\n",
    "    vocab['<END>'] = 3\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    return vocab,vocab_size\n",
    "def encode_sentences(sentences,vocab,max_len=25):\n",
    "    encoded_sentences = [\n",
    "        [vocab['<START>']] +\n",
    "        [vocab.get(token, vocab['<UNK>']) for token in sentence]\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "\n",
    "    for i, sentence in enumerate(encoded_sentences):\n",
    "        if len(sentence) > max_len - 1:\n",
    "            encoded_sentences[i] = sentence[:max_len - 1]\n",
    "\n",
    "    for i, sentence in enumerate(encoded_sentences):\n",
    "        sentence.append(vocab['<END>'])\n",
    "\n",
    "    padded_sentences = []\n",
    "\n",
    "\n",
    "    for sentence in encoded_sentences:\n",
    "        while len(sentence) < max_len:\n",
    "            sentence.append(vocab['<PAD>'])\n",
    "        padded_sentences.append(sentence)\n",
    "    return padded_sentences\n",
    "\n",
    "ar_vocab , ar_vocab_size = build_vocab(data['ar_tokens'])\n",
    "en_vocab , en_vocab_size = build_vocab(data['en_tokens'])\n",
    "max_len = 35\n",
    "data['ar_ids'] = encode_sentences(data['ar_tokens'],ar_vocab, max_len=max_len)\n",
    "data['en_ids'] = encode_sentences(data['en_tokens'],en_vocab, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "n5X7XdCekLOu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train (80%), validation (10%), and test (10%) sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42,shuffle=True)\n",
    "\n",
    "# If you want a separate test set, further split val_data\n",
    "val_data, test_data = train_test_split(val_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qgr3GGy_kNUn"
   },
   "outputs": [],
   "source": [
    "# Convert the train, validation, and test data to PyTorch tensors\n",
    "train_en_tensor = torch.tensor(train_data['en_ids'].tolist())\n",
    "train_ar_tensor = torch.tensor(train_data['ar_ids'].tolist())\n",
    "\n",
    "val_en_tensor = torch.tensor(val_data['en_ids'].tolist())\n",
    "val_ar_tensor = torch.tensor(val_data['ar_ids'].tolist())\n",
    "\n",
    "test_en_tensor = torch.tensor(test_data['en_ids'].tolist())\n",
    "test_ar_tensor = torch.tensor(test_data['ar_ids'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "czd-IhNlkPkg"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_tensor, tgt_tensor):\n",
    "        self.src_tensor = src_tensor  # Source (English)\n",
    "        self.tgt_tensor = tgt_tensor  # Target (Arabic)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.src_tensor[idx], self.tgt_tensor[idx]\n",
    "\n",
    "# Create datasets for training, validation, and testing\n",
    "train_dataset = TranslationDataset(train_en_tensor, train_ar_tensor)\n",
    "val_dataset = TranslationDataset(val_en_tensor, val_ar_tensor)\n",
    "test_dataset = TranslationDataset(test_en_tensor, test_ar_tensor)\n",
    "\n",
    "# Create DataLoaders to iterate through batches\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dL7CAQxVkSg8"
   },
   "outputs": [],
   "source": [
    "# building the model\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_model,n_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_len = d_model // n_heads\n",
    "\n",
    "        self.key = nn.Linear(d_model , d_model)\n",
    "        self.query = nn.Linear(d_model , d_model)\n",
    "        self.value = nn.Linear(d_model , d_model)\n",
    "        self.linear = nn.Linear(d_model , d_model)\n",
    "\n",
    "    def K_dot_Q(self ,key , query , value, mask):\n",
    "        result = torch.matmul(query , key.transpose(-2,-1)) / math.sqrt(self.head_len)\n",
    "        if mask is not None:\n",
    "            result = result.masked_fill(mask == 0, -1e9)\n",
    "        result_probs = torch.softmax(result , dim=-1)\n",
    "        out = torch.matmul(result_probs,value)\n",
    "        return out\n",
    "\n",
    "    def split_heads(self, x):\n",
    "      batch_size, seq_len, d_model = x.size()\n",
    "      return x.view(batch_size, seq_len, self.n_heads, self.head_len).transpose(1, 2)\n",
    "\n",
    "    def concatinate_heads(self, x):\n",
    "      batch_size, n_heads, seq_len, head_len = x.size()\n",
    "      return x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "\n",
    "    def forward(self,k,q,v,mask = None):\n",
    "        K = self.split_heads(self.key(k))\n",
    "        Q = self.split_heads(self.query(q))\n",
    "        V = self.split_heads(self.value(v))\n",
    "        out = self.K_dot_Q(K , Q , V, mask)\n",
    "\n",
    "        conc_out = self.concatinate_heads(out)\n",
    "        final_out = self.linear(conc_out)\n",
    "        return final_out\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward (nn.Module):\n",
    "    def __init__(self,d_model , d_ff ):\n",
    "        super(FeedForward,self).__init__()\n",
    "        self.layer1 = nn.Linear(d_model, d_ff)\n",
    "        self.layer2 = nn.Linear(d_ff, d_model)\n",
    "        self.activation = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        l1 = self.activation(self.layer1(x))\n",
    "        l2 = self.layer2(l1)\n",
    "        return l2\n",
    "\n",
    "\n",
    "\n",
    "class Embed_PosEncod(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, d_model):\n",
    "        super(Embed_PosEncod, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_encod = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "    def forward(self, x,device):\n",
    "        batch, seq_len = x.size()\n",
    "        x_tock = self.embedding(x).to(device)\n",
    "        x_positions = self.position_encod(torch.arange(seq_len, device=device))\n",
    "        return x_tock + x_positions\n",
    "\n",
    "\n",
    "\n",
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,d_ff,dropout):\n",
    "        super(Encoder_layer,self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model,n_heads)\n",
    "        self.Norm1 = nn.LayerNorm(d_model)\n",
    "        self.Norm2 = nn.LayerNorm(d_model)\n",
    "        self.feed = FeedForward(d_model , d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self,x,mask):\n",
    "        out = self.attention(x,x,x,None)\n",
    "        norm1 = self.Norm1(self.dropout(out)+x)\n",
    "        out = self.feed(norm1)\n",
    "        norm2 = self.Norm2(self.dropout(out)+norm1)\n",
    "        return norm2\n",
    "\n",
    "\n",
    "class Decoder_layer(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,d_ff,dropout):\n",
    "        super(Decoder_layer,self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model,n_heads)\n",
    "        self.cross_attention = MultiHeadAttention(d_model,n_heads)\n",
    "        self.Norm1 = nn.LayerNorm(d_model)\n",
    "        self.Norm2 = nn.LayerNorm(d_model)\n",
    "        self.Norm3 = nn.LayerNorm(d_model)\n",
    "        self.feed = FeedForward(d_model , d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self,x,enc_out,trg_mask, src_mask):\n",
    "        out = self.attention(x,x,x,trg_mask)\n",
    "        norm1 = self.Norm1(self.dropout(out)+x)\n",
    "        out = self.cross_attention(enc_out , norm1 , enc_out , src_mask)\n",
    "        norm2 = self.Norm2(self.dropout(out)+norm1)\n",
    "        out = self.feed(norm2)\n",
    "        norm3 = self.Norm3(self.dropout(out)+norm2)\n",
    "        return norm3\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, tgt_vocab_size, max_seq_len, d_model, n_heads, d_ff, dropout, num_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.enc_embed_pos = Embed_PosEncod(vocab_size, max_seq_len, d_model)\n",
    "        self.dec_embed_pos = Embed_PosEncod(tgt_vocab_size, max_seq_len, d_model)\n",
    "        self.encoders = nn.ModuleList([Encoder_layer(d_model, n_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoders = nn.ModuleList([Decoder_layer(d_model, n_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.linear_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "      device = src.device\n",
    "\n",
    "      src_mask = (src != 0).unsqueeze(1).unsqueeze(2).to(device)\n",
    "\n",
    "      seq_len = tgt.size(1)\n",
    "      tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2).to(device)\n",
    "\n",
    "      nopeak_mask = torch.triu(torch.ones(1, seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "\n",
    "      tgt_mask = tgt_mask & nopeak_mask.unsqueeze(0)\n",
    "      return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask,tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embeded = self.dropout(self.enc_embed_pos(src, src.device))\n",
    "        tgt_embeded = self.dropout(self.dec_embed_pos(tgt, tgt.device))\n",
    "        enc_output = src_embeded\n",
    "        for encoder_layer in self.encoders:\n",
    "            enc_output = encoder_layer(enc_output,src_mask)\n",
    "\n",
    "        dec_output = tgt_embeded\n",
    "        for decoder_layer in self.decoders:\n",
    "            dec_output = decoder_layer(dec_output, enc_output, tgt_mask,src_mask)\n",
    "        out = self.linear_out(dec_output)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "vM2t-wmm2YjC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "flat_ar_ids = [idx for word,idx in  ar_vocab.items() ]\n",
    "unique_classes = np.unique(flat_ar_ids)\n",
    "class_weights = compute_class_weight('balanced', classes=unique_classes, y=flat_ar_ids)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "vocab_size = ar_vocab_size\n",
    "extended_class_weights_tensor = torch.zeros(vocab_size).to(device)\n",
    "\n",
    "for idx, class_id in enumerate(unique_classes):\n",
    "    extended_class_weights_tensor[class_id] = class_weights_tensor[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgJyxDOHkUhl"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:, :-1].to(device)\n",
    "        tgt_output = tgt[:, 1:].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_input)\n",
    "\n",
    "        # Calculate the loss (Ignoring padding tokens)\n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        _, predicted = output.max(dim=-1)  t\n",
    "        mask = (tgt_output != 0)\n",
    "        correct_predictions += ((predicted == tgt_output) & mask).sum().item()  \n",
    "        total_predictions += mask.sum().item()\n",
    "\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    return epoch_loss / len(train_loader), epoch_accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1].to(device)\n",
    "            tgt_output = tgt[:, 1:].to(device)\n",
    "\n",
    "            output = model(src, tgt_input)\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = output.max(dim=-1)\n",
    "            mask = (tgt_output != 0)\n",
    "            correct_predictions += ((predicted == tgt_output) & mask).sum().item()\n",
    "            total_predictions += mask.sum().item()\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "    return val_loss / len(val_loader), val_accuracy\n",
    "\n",
    "def translate(model, input_sentence, max_len, sos_token, eos_token, device='cuda'):\n",
    "\n",
    "    src_tokens = encode_sentences([input_sentence.split()], ar_vocab, max_len=max_len)[0]\n",
    "    src_tensor = torch.tensor([src_tokens], dtype=torch.long).to(device)  # shape: [1, seq_len]\n",
    "    model.eval()\n",
    "    tgt = torch.tensor([[sos_token]], dtype=torch.long).to(device)  \n",
    "    for index in range(max_len - 1):\n",
    "        output = model(src_tensor, tgt)\n",
    "\n",
    "        next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "        tgt = torch.cat([tgt, next_token], dim=1)\n",
    "\n",
    "        if next_token.item() == eos_token:\n",
    "            break\n",
    "\n",
    "    translated_tokens = tgt.squeeze(0).cpu().numpy()  \n",
    "    translated_sentence = ' '.join([' '.join([word for word, idx in ar_vocab.items() if idx == token]) for token in translated_tokens[1:] if token != en_vocab['<PAD>']])\n",
    "    return translated_sentence\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs=10, lr=5e-5, batch_size=32, device='cuda', warmup_steps=1000,test_sentence='hello'):\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0, weight=extended_class_weights_tensor)  \n",
    "\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=warmup_steps,  \n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Train for one epoch\n",
    "        train_loss, train_accuracy = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        translated_sentence = translate(model, test_sentence, max_len=max_len,sos_token=ar_vocab['<START>'], eos_token=ar_vocab['<END>'])\n",
    "        print(f'input : {test_sentence}');\n",
    "        print(f'translated : {translated_sentence}')\n",
    "        scheduler.step()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Rj-wmFStkW5R"
   },
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size=en_vocab_size, tgt_vocab_size=ar_vocab_size, d_model=512, n_heads=8,\n",
    "                    num_layers=3, d_ff=2048, dropout=0.4,max_seq_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nz6RiBpukYSk",
    "outputId": "6a254f36-f4b5-4146-cb69-6b808e581d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Training loss: 9.4330, Training accuracy: 0.0001\n",
      "Validation loss: 9.4152, Validation accuracy: 0.0001\n",
      "input : hello\n",
      "translated : ملايين وفي غناك وعده سأشتاق لفتت والمنجل سأخفف لها طفولة عامي ألزمت البترول كثر نلتق راهبا تقولي دكتورا نادلا أنسى حضوري خريطة خريطة الغيوم الافلام اسألها النسيان أنتم المتحدة للميلاد القادمة لقراءة خلال تعشق\n",
      "Epoch 2/20\n",
      "Training loss: 5.9988, Training accuracy: 0.3026\n",
      "Validation loss: 5.3478, Validation accuracy: 0.3634\n",
      "input : hello\n",
      "translated : هل توم أن أن <END>\n",
      "Epoch 3/20\n",
      "Training loss: 4.7311, Training accuracy: 0.4488\n",
      "Validation loss: 4.1711, Validation accuracy: 0.5223\n",
      "input : hello\n",
      "translated : هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل هل\n",
      "Epoch 4/20\n",
      "Training loss: 3.9260, Training accuracy: 0.5455\n",
      "Validation loss: 3.5292, Validation accuracy: 0.5950\n",
      "input : hello\n",
      "translated : كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم كم\n",
      "Epoch 5/20\n",
      "Training loss: 3.4104, Training accuracy: 0.6031\n",
      "Validation loss: 3.0961, Validation accuracy: 0.6436\n",
      "input : hello\n",
      "translated : كن كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل\n",
      "Epoch 6/20\n",
      "Training loss: 2.9893, Training accuracy: 0.6486\n",
      "Validation loss: 2.7529, Validation accuracy: 0.6845\n",
      "input : hello\n",
      "translated : كن كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل كل\n",
      "Epoch 7/20\n",
      "Training loss: 2.6379, Training accuracy: 0.6833\n",
      "Validation loss: 2.4665, Validation accuracy: 0.7156\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 8/20\n",
      "Training loss: 2.3296, Training accuracy: 0.7167\n",
      "Validation loss: 2.2475, Validation accuracy: 0.7391\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 9/20\n",
      "Training loss: 2.0703, Training accuracy: 0.7466\n",
      "Validation loss: 2.0687, Validation accuracy: 0.7610\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 10/20\n",
      "Training loss: 1.8478, Training accuracy: 0.7721\n",
      "Validation loss: 1.9212, Validation accuracy: 0.7811\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 11/20\n",
      "Training loss: 1.6628, Training accuracy: 0.7928\n",
      "Validation loss: 1.8136, Validation accuracy: 0.7954\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 12/20\n",
      "Training loss: 1.5132, Training accuracy: 0.8127\n",
      "Validation loss: 1.7300, Validation accuracy: 0.8050\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 13/20\n",
      "Training loss: 1.3976, Training accuracy: 0.8262\n",
      "Validation loss: 1.6713, Validation accuracy: 0.8127\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 14/20\n",
      "Training loss: 1.2999, Training accuracy: 0.8387\n",
      "Validation loss: 1.6121, Validation accuracy: 0.8194\n",
      "input : hello\n",
      "translated : من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من\n",
      "Epoch 15/20\n",
      "Training loss: 1.2242, Training accuracy: 0.8468\n",
      "Validation loss: 1.5696, Validation accuracy: 0.8239\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 16/20\n",
      "Training loss: 1.1601, Training accuracy: 0.8545\n",
      "Validation loss: 1.5301, Validation accuracy: 0.8301\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 17/20\n",
      "Training loss: 1.1148, Training accuracy: 0.8596\n",
      "Validation loss: 1.5132, Validation accuracy: 0.8308\n",
      "input : hello\n",
      "translated : أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر أشعر\n",
      "Epoch 18/20\n",
      "Training loss: 1.0890, Training accuracy: 0.8620\n",
      "Validation loss: 1.4858, Validation accuracy: 0.8359\n",
      "input : hello\n",
      "translated : أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا أنا\n",
      "Epoch 19/20\n",
      "Training loss: 1.0766, Training accuracy: 0.8632\n",
      "Validation loss: 1.4763, Validation accuracy: 0.8363\n",
      "input : hello\n",
      "translated : يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك يمكنك\n",
      "Epoch 20/20\n",
      "Training loss: 1.0804, Training accuracy: 0.8630\n",
      "Validation loss: 1.4706, Validation accuracy: 0.8378\n",
      "input : hello\n",
      "translated : من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من من\n"
     ]
    }
   ],
   "source": [
    "train_losses ,val_losses, train_accuracies, val_accuracies = train(model=model,train_loader=train_loader,val_loader=val_loader,num_epochs=20,lr=3e-2,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MUy9PEik-rQ",
    "outputId": "20368612-3e30-45aa-fe2e-29b743509216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3676 test accuracy : 0.8515\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, device):\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in test_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1].to(device)  \n",
    "            tgt_output = tgt[:, 1:].to(device)  \n",
    "\n",
    "            output = model(src, tgt_input)\n",
    "\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = output.max(dim=-1)              \n",
    "            mask = (tgt_output != 0) \n",
    "            correct_predictions += ((predicted == tgt_output) & mask).sum().item() \n",
    "            total_predictions += mask.sum().item()\n",
    "            val_accuracy = correct_predictions / total_predictions\n",
    "    return val_loss / len(test_loader),val_accuracy\n",
    "test_loss,val_accuracy = test(model, test_loader, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} test accuracy : {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
